{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05482a6",
   "metadata": {},
   "source": [
    "# Задача 9. Hand-crafted graph features\n",
    "\n",
    "* **Дедлайн**: 16.05.2025, 23:59\n",
    "* Основной полный балл: 5\n",
    "* Максимум баллов: 10\n",
    "\n",
    "\n",
    "## Задача\n",
    "\n",
    "- [x] Найти или сгенерировать набор данных для бинарной классификации графов.\n",
    "- [x] Реализовать функцию `shortest_path_kernel(train_graphs, test_graphs)`, которая принимает тренировочный и тестовые наборы, а возвращает пару `K_train, K_test`\n",
    "  - Опишите графы с помощью вектора из количества кратчайших путей различной длины\n",
    "  - Для вычисления длин кратчайших путей можно использовать `nx.shortest_path_length(G)`\n",
    "  - Ядровая функция для сравнения двух графов - скалярное произведение их двух векторов\n",
    "  - `K_train` - матрица из ядровых функций для сравнения тренировочных графов между собой\n",
    "  - `K_test` - матрица из ядровых функций для сравнения тестовых графов с тренировочными\n",
    "- [x] Используя реализованное ядро обучите модель SVC, подберите гиперпараметры, вычислите различные метрики качества\n",
    "- [x] (+5 баллов) Также реализовать Weisfeiler-Lehman Kernel и обучить классификатор с ним, сравнить результаты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f89376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc8ae5",
   "metadata": {},
   "source": [
    "## Генерация данных (\"с центральным узлом\" vs. \"без центрального узла\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "503d4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=7)\n",
    "\n",
    "def generate_star_graph_variant(n_nodes):\n",
    "    if rng.random() > 0.5:\n",
    "        return nx.star_graph(n_nodes - 1)\n",
    "    else:\n",
    "        G = nx.star_graph(n_nodes - 1)\n",
    "        u, v = rng.choice(n_nodes, 2, replace=False)\n",
    "        if not G.has_edge(u, v):\n",
    "            G.add_edge(u, v)\n",
    "        return G\n",
    "\n",
    "def generate_uniform_graph_variant(n_nodes):\n",
    "    if rng.random() > 0.5:\n",
    "        return nx.path_graph(n_nodes)\n",
    "    else:\n",
    "        return nx.grid_2d_graph(int(np.sqrt(n_nodes)), int(np.sqrt(n_nodes)))\n",
    "\n",
    "def generate_center_dataset(n_samples=300, max_nodes=20):\n",
    "    data, targets = [], []\n",
    "    for _ in range(n_samples // 2):\n",
    "        nodes = rng.integers(5, max_nodes)\n",
    "        data.append(generate_star_graph_variant(nodes))\n",
    "        targets.append(1)\n",
    "        data.append(generate_uniform_graph_variant(nodes))\n",
    "        targets.append(0)\n",
    "    return data, np.array(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc855fd",
   "metadata": {},
   "source": [
    "## Shortest path kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "613a1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shortest_path_vector(graph, max_len=7):\n",
    "    sp_lengths = dict(nx.shortest_path_length(graph))\n",
    "    features = np.zeros(max_len, dtype=np.float32)\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "\n",
    "    for src in sp_lengths:\n",
    "        for dst, dist in sp_lengths[src].items():\n",
    "            if src != dst and dist <= max_len:\n",
    "                features[dist - 1] += 1\n",
    "\n",
    "    if num_nodes > 1:\n",
    "        features /= (num_nodes * (num_nodes - 1))\n",
    "    return features\n",
    "\n",
    "def shortest_path_kernel(train_g, test_g, max_len=7):\n",
    "    train_feats = np.array([extract_shortest_path_vector(g, max_len) for g in train_g])\n",
    "    test_feats = np.array([extract_shortest_path_vector(g, max_len) for g in test_g])\n",
    "    return train_feats @ train_feats.T, test_feats @ train_feats.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9e227",
   "metadata": {},
   "source": [
    "## Weisfeiler-Lehman Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dfc15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WLKernel(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, h=3, norm=True):\n",
    "        self.h = h\n",
    "        self.norm = norm\n",
    "        self.label_map = {}\n",
    "        self._fit_graphs = []\n",
    "\n",
    "    def _wl_step(self, G, labels):\n",
    "        new = {}\n",
    "        for node in G:\n",
    "            neigh = sorted(labels[nei] for nei in G.neighbors(node))\n",
    "            key = (labels[node], tuple(neigh))\n",
    "            if key not in self.label_map:\n",
    "                self.label_map[key] = len(self.label_map) + 1\n",
    "            new[node] = self.label_map[key]\n",
    "        return new\n",
    "\n",
    "    def _graph_feature_vector(self, G):\n",
    "        labels = {n: 1 for n in G}\n",
    "        feature_counts = defaultdict(int)\n",
    "        for l in labels.values():\n",
    "            feature_counts[l] += 1\n",
    "        for _ in range(self.h):\n",
    "            labels = self._wl_step(G, labels)\n",
    "            for l in labels.values():\n",
    "                feature_counts[l] += 1\n",
    "        return feature_counts\n",
    "\n",
    "    def fit(self, graphs, y=None):\n",
    "        self.label_map.clear()\n",
    "        self._fit_graphs = graphs\n",
    "        for g in graphs:\n",
    "            self._graph_feature_vector(g)\n",
    "        return self\n",
    "\n",
    "    def transform(self, graphs):\n",
    "        base_vecs = [self._graph_feature_vector(g) for g in self._fit_graphs]\n",
    "        target_vecs = [self._graph_feature_vector(g) for g in graphs]\n",
    "        K = np.zeros((len(graphs), len(base_vecs)))\n",
    "        for i, vec1 in enumerate(target_vecs):\n",
    "            for j, vec2 in enumerate(base_vecs):\n",
    "                keys = set(vec1) & set(vec2)\n",
    "                val = sum(vec1[k] * vec2[k] for k in keys)\n",
    "                if self.norm:\n",
    "                    norm1 = np.sqrt(sum(v ** 2 for v in vec1.values()))\n",
    "                    norm2 = np.sqrt(sum(v ** 2 for v in vec2.values()))\n",
    "                    val /= (norm1 * norm2 + 1e-10)\n",
    "                K[i, j] = val\n",
    "        return K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3d21e",
   "metadata": {},
   "source": [
    "## Обучение и оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2af0248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPK Accuracy: 1.0\n",
      "SPK F1: 1.0\n",
      "WLK Accuracy: 1.0\n",
      "WLK F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "graphs, labels = generate_center_dataset(1000, max_nodes=16)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(graphs, labels, test_size=0.25, random_state=1)\n",
    "\n",
    "# Shortest Path Kernel\n",
    "K_tr_sp, K_te_sp = shortest_path_kernel(X_tr, X_te)\n",
    "clf_sp = GridSearchCV(SVC(kernel='precomputed'), {'C': [0.01, 0.1, 1, 10]}, cv=5)\n",
    "clf_sp.fit(K_tr_sp, y_tr)\n",
    "y_pred_sp = clf_sp.predict(K_te_sp)\n",
    "\n",
    "print(\"SPK Accuracy:\", accuracy_score(y_te, y_pred_sp))\n",
    "print(\"SPK F1:\", f1_score(y_te, y_pred_sp))\n",
    "\n",
    "# Weisfeiler-Lehman Kernel\n",
    "wlk = WLKernel(h=4)\n",
    "wlk.fit(X_tr)\n",
    "K_tr_wl = wlk.transform(X_tr)\n",
    "K_te_wl = wlk.transform(X_te)\n",
    "\n",
    "clf_wl = GridSearchCV(SVC(kernel='precomputed'), {'C': [0.01, 1, 100]}, cv=5)\n",
    "clf_wl.fit(K_tr_wl, y_tr)\n",
    "y_pred_wl = clf_wl.predict(K_te_wl)\n",
    "\n",
    "print(\"WLK Accuracy:\", accuracy_score(y_te, y_pred_wl))\n",
    "print(\"WLK F1:\", f1_score(y_te, y_pred_wl))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89781779",
   "metadata": {},
   "source": [
    "## Сравнение Weisfeiler-Lehman Kernel и Shortest Path Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b028c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение:\n",
      "Shortest Path: acc=1.000, f1=1.000\n",
      "Weisfeiler-Lehman: acc=1.000, f1=1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nСравнение:\")\n",
    "print(f\"Shortest Path: acc={accuracy_score(y_te, y_pred_sp):.3f}, f1={f1_score(y_te, y_pred_sp):.3f}\")\n",
    "print(f\"Weisfeiler-Lehman: acc={accuracy_score(y_te, y_pred_wl):.3f}, f1={f1_score(y_te, y_pred_wl):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
